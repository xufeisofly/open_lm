epoch: 1.25T
dataset: bigdata
num_params: 1B
max_seq_len: 2048
seed: 1
precision: fp32

# Tokenizer
tokenizer:
  # name: [Add name from memory]
  pretrained_model_name_or_path: 
  kwargs:
    model_max_length: 2048

model:
  name: open_lm
  # pretrained_model_name_or_path: [add name from memory]
  init_device: cpu
  pretrained: true

load_path: # Add your (optional) Composer checkpoint path here!

device_eval_batch_size: 8

# FSDP config for model sharding
fsdp_config:
  sharding_strategy: FULL_SHARD
  mixed_precision: FULL


icl_tasks:
-
  label: agi_eval_lsat_rc
  dataset_uri: local_data/reading_comprehension/agi_eval_lsat_rc.jsonl
  num_fewshot: [3]
  icl_task_type: multiple_choice
-
  label: agi_eval_lsat_lr
  dataset_uri: local_data/reading_comprehension/agi_eval_lsat_lr.jsonl
  num_fewshot: [3]
  icl_task_type: multiple_choice
-
  label: agi_eval_sat_en
  dataset_uri: local_data/reading_comprehension/agi_eval_sat_en.jsonl
  num_fewshot: [3]
  icl_task_type: multiple_choice
-
  label: agi_eval_sat_math_cot
  dataset_uri: local_data/symbolic_problem_solving/agi_eval_sat_math.jsonl
  num_fewshot: [3]
  icl_task_type: generation_task_with_answers
  cot_delimiter: ' #### '
  continuation_delimiter: "\nA: Let's think step by step. "
  question_prelimiter: "Q: "
  early_stopping_criteria:
    - "\n\n"
    - "Q:"
    - "Q: "
-
  label: aqua_cot
  dataset_uri: local_data/symbolic_problem_solving/aqua.jsonl
  num_fewshot: [3]
  icl_task_type: generation_task_with_answers
  cot_delimiter: ' #### '
  continuation_delimiter: "\nA: Let's think step by step. "
  question_prelimiter: "Q: "
  early_stopping_criteria:
    - "\n\n"
    - "Q:"
    - "Q: "
-
  label: bbq
  dataset_uri: local_data/safety/bbq.jsonl
  num_fewshot: [3]
  icl_task_type: multiple_choice
  has_categories: true
-
  label: bigbench_conceptual_combinations
  dataset_uri: local_data/language_understanding/bigbench_conceptual_combinations.jsonl
  num_fewshot: [10]
  icl_task_type: multiple_choice
-
  label: bigbench_conlang_translation
  dataset_uri: local_data/language_understanding/bigbench_conlang_translation.jsonl
  num_fewshot: [0]
  icl_task_type: language_modeling
-
  label: bigbench_elementary_math_qa
  dataset_uri: local_data/symbolic_problem_solving/bigbench_elementary_math_qa.jsonl
  num_fewshot: [10]
  icl_task_type: multiple_choice
-
  label: bigbench_logical_deduction
  dataset_uri: local_data/symbolic_problem_solving/bigbench_logical_deduction.jsonl
  num_fewshot: [10]
  icl_task_type: multiple_choice
-
  label: bigbench_misconceptions
  dataset_uri: local_data/world_knowledge/bigbench_misconceptions.jsonl
  num_fewshot: [10]
  icl_task_type: multiple_choice
-
  label: bigbench_novel_concepts
  dataset_uri: local_data/commonsense_reasoning/bigbench_novel_concepts.jsonl
  num_fewshot: [10]
  icl_task_type: multiple_choice
-
  label: bigbench_strange_stories
  dataset_uri: local_data/commonsense_reasoning/bigbench_strange_stories.jsonl
  num_fewshot: [10]
  icl_task_type: multiple_choice
-
  label: bigbench_strategy_qa
  dataset_uri: local_data/commonsense_reasoning/bigbench_strategy_qa.jsonl
  num_fewshot: [10]
  icl_task_type: multiple_choice
-
  label: bigbench_understanding_fables
  dataset_uri: local_data/reading_comprehension/bigbench_understanding_fables.jsonl
  num_fewshot: [10]
  icl_task_type: multiple_choice
-
  label: enterprise_pii_classification
  dataset_uri: local_data/safety/enterprise_pii_classification.jsonl
  num_fewshot: [10]
  icl_task_type: multiple_choice
-
  label: gpqa_main
  dataset_uri: gpqa_data/gpqa_main.jsonl
  num_fewshot: [5]
  icl_task_type: multiple_choice
  continuation_delimiter: "\nAnswer: "
-
  label: gsm8k_cot
  dataset_uri: local_data/symbolic_problem_solving/gsm8k.jsonl
  num_fewshot: [3]
  icl_task_type: generation_task_with_answers
  cot_delimiter: ' #### '
  continuation_delimiter: "\nA: Let's think step by step. "
  question_prelimiter: "Q: "
  early_stopping_criteria:
    - "\n\n"
    - "Q:"
    - "Q: "
-
  label: logi_qa
  dataset_uri: local_data/symbolic_problem_solving/logi_qa.jsonl
  num_fewshot: [10]
  icl_task_type: multiple_choice
  continuation_delimiter: "\nAnswer: " # this separates questions from answers
-
  label: bigbench_elementary_math_qa
  dataset_uri: local_data/symbolic_problem_solving/bigbench_elementary_math_qa.jsonl
  num_fewshot: [10]
  icl_task_type: multiple_choice
-
  label: pubmed_qa_labeled
  dataset_uri: local_data/reading_comprehension/pubmed_qa_labeled.jsonl
  num_fewshot: [10]
  icl_task_type: language_modeling
-
  label: simple_arithmetic_withspaces
  dataset_uri: local_data/symbolic_problem_solving/simple_arithmetic_withspaces.jsonl
  num_fewshot: [10]
  icl_task_type: language_modeling
-
  label: svamp_cot
  dataset_uri: local_data/symbolic_problem_solving/svamp.jsonl
  num_fewshot: [3]
  icl_task_type: generation_task_with_answers
  continuation_delimiter: "\nUsing the formula below:\n"
  cot_delimiter: ' #### '
  question_prelimiter: "Q: "
  early_stopping_criteria:
  - "\n\n"
  - "Q:"
  - "Q: "
-
  label: triviaqa_sm_sub
  dataset_uri: local_data/world_knowledge/triviaqa_sm_sub.jsonl
  num_fewshot: [0]
  icl_task_type: generation_task_with_answers
-
  label: winogender_mc_female
  dataset_uri: local_data/safety/winogender_mc_female.jsonl
  num_fewshot: [0]
  icl_task_type: multiple_choice
-
  label: winogender_mc_male
  dataset_uri: local_data/safety/winogender_mc_male.jsonl
  num_fewshot: [0]
  icl_task_type: multiple_choice






































